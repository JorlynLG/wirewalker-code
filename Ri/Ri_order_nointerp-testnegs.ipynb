{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gsw\n",
    "import scipy.signal as sp\n",
    "import datetime as dt\n",
    "from beam2ENU import beam2ENU\n",
    "import seawater as sw\n",
    "import oceans as oc\n",
    "from scipy.interpolate import griddata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directory = '../../Data/deployment_raw/';\n",
    "outdir = '../../plots/Ri/Ri_profile/';\n",
    "deployment_name = 'deploy1_';\n",
    "measurement_type = 'ctd_';\n",
    "file_type = 'raw_'\n",
    "grid = pd.DataFrame(columns=['N2','shr2','Ri']) # Note that there are now row data inserted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_data(directory, c_file, a_file):\n",
    "    #Open the CTD data file that has all data stored as pandas\n",
    "    c_data = pd.read_pickle(directory+deployment_name+file_type+c_file)\n",
    "    a_data = pd.read_pickle(directory+deployment_name+file_type+a_file)\n",
    "\n",
    "    #Join CTD and ADCP data together (add time to CTD data)\n",
    "    start_time = a_data[\"a_time\"].values[1][:-10]\n",
    "    start_time = dt.datetime.strptime(start_time,\"%Y-%m-%dT%H:%M:%S\")\n",
    "    start_time = start_time - dt.timedelta(seconds=15)\n",
    "    c_data[\"c_time\"] = [start_time+dt.timedelta(seconds=x) for x in range(len(c_data[\"c_temp\"].values))]\n",
    "    c_data.index = pd.DatetimeIndex(c_data['c_time'])\n",
    "\n",
    "    #And average ADCP to resample at 1Hz\n",
    "    a_data.index = pd.DatetimeIndex(a_data['a_time'])\n",
    "    a_data = a_data.resample('S').mean()\n",
    "    #Combine both datasets into one dataset by time\n",
    "    data = pd.concat([a_data, c_data], axis=1, sort=False).dropna(axis='rows')\n",
    "    data_start = data.index[data[\"c_pres\"]>20][0]\n",
    "    data_end = data.index[data[\"c_pres\"]>100][0]\n",
    "    data = data[data_start:data_end]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def buoyancy_freq(data):\n",
    "#     #Get buoyancy frequency\n",
    "#     CT = gsw.CT_from_t(data['c_sal'],data['c_temp'],data['c_pres'])\n",
    "#     SA = gsw.SA_from_SP(data['c_sal'],data['c_pres'],174,-43)\n",
    "#     [N2,p_mid,dp] = gsw.Nsquared(SA,CT,data['c_pres'])\n",
    "#     #[n2,q,p_ave] = sw.bfrq(data['c_sal'],data['c_temp'],data['c_pres'],-43)\n",
    "#     #N2 = [item[0] for item in n2]\n",
    "#     N2 = np.array(N2)\n",
    "#     data['N2'] = np.append(N2,N2[-1])\n",
    "\n",
    "#     #filter buoyancy frequency by removing outliers\n",
    "#     data['N2'] = data[\"N2\"].replace([np.inf, -np.inf], np.nan)\n",
    "#     data['N2'] = data['N2'].mask(((data['N2']-data['N2'].mean()).abs() > data['N2'].std()))\n",
    "#     data['N2'] = data['N2'].interpolate().rolling(10).mean().abs()\n",
    "#     #data['N2'] = data['N2'].mask(((data['N2']-data['N2'].mean()).abs() > 3*data['N2'].std()))\n",
    "#     #data['N2'] = data['N2'].interpolate()\n",
    "#     #plt.plot(data['N2'])\n",
    "#     #plt.show()\n",
    "#     return data\n",
    "def buoyancy_freq(data):\n",
    "    #Get buoyancy frequency\n",
    "    dp = np.diff(data['c_pres'].values,axis=0)\n",
    "    data['dp'] = np.append(dp,dp[-1])\n",
    "    data['dp'] = data['dp'].mask(((data['dp']-data['dp'].mean()).abs() > data['dp'].std()))\n",
    "    data['dp'] = data['dp'].interpolate().rolling(5).mean()\n",
    "    CT = gsw.CT_from_t(data['c_sal'],data['c_temp'],data['c_pres'])\n",
    "    SA = gsw.SA_from_SP(data['c_sal'],data['c_pres'],174,-43)\n",
    "    pdens = gsw.sigma0(SA, CT)\n",
    "    data['pdens'] = pdens\n",
    "    dpdens = np.diff(data['pdens'].values,axis=0)\n",
    "    data['dpdens'] = np.append(dpdens,dpdens[-1])\n",
    "    data['dpdens'] = data['dpdens'].mask(((data['dpdens']-data['dpdens'].mean()).abs() > data['dpdens'].std()))\n",
    "    data['dpdens'] = data['dpdens'].interpolate().rolling(5).mean()    \n",
    "    data['N2'] = (9.7963*data['dpdens'])/(data['pdens']*data['dp'])\n",
    "    print(data['N2'])\n",
    "\n",
    "    #filter buoyancy frequency by removing outliers\n",
    "    #data['N2'] = data['N2'].mask(data['N2']< 0.000005)\n",
    "    data['N2'] = data[\"N2\"].replace([np.inf, -np.inf], np.nan)\n",
    "    data['N2'] = data['N2'].mask(((data['N2']-data['N2'].mean()).abs() > data['N2'].std()))\n",
    "    data['N2'] = data['N2'].interpolate().rolling(10).mean().abs()\n",
    "    #data['N2'] = data['N2'].mask(((data['N2']-data['N2'].mean()).abs() > 3*data['N2'].std()))\n",
    "    #data['N2'] = data['N2'].interpolate()\n",
    "    \n",
    "    #Sorted\n",
    "    data['pdens_sort'] = np.sort(pdens)\n",
    "    dpdens_sort = np.diff(data['pdens_sort'].values,axis=0)\n",
    "    data['dpdens_sort'] = np.append(dpdens_sort,dpdens_sort[-1])\n",
    "    data['dpdens_sort'] = data['dpdens_sort'].mask(((data['dpdens_sort']-data['dpdens_sort'].mean()).abs() > data['dpdens_sort'].std()))\n",
    "    data['dpdens_sort'] = data['dpdens_sort'].interpolate().rolling(5).mean()    \n",
    "    data['N2_sort'] = (9.7963*data['dpdens_sort'])/(data['pdens_sort']*data['dp'])    \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-09 02:07:27         NaN\n",
      "2018-06-09 02:07:28         NaN\n",
      "2018-06-09 02:07:29         NaN\n",
      "2018-06-09 02:07:30         NaN\n",
      "2018-06-09 02:07:31    0.001489\n",
      "2018-06-09 02:07:32    0.001200\n",
      "2018-06-09 02:07:33    0.001266\n",
      "2018-06-09 02:07:34    0.001213\n",
      "2018-06-09 02:07:35    0.001293\n",
      "2018-06-09 02:07:36    0.001649\n",
      "2018-06-09 02:07:37    0.001776\n",
      "2018-06-09 02:07:38    0.002016\n",
      "2018-06-09 02:07:39    0.002333\n",
      "2018-06-09 02:07:40    0.002560\n",
      "2018-06-09 02:07:41    0.002098\n",
      "2018-06-09 02:07:42    0.002227\n",
      "2018-06-09 02:07:43    0.001616\n",
      "2018-06-09 02:07:44    0.000848\n",
      "2018-06-09 02:07:45    0.000295\n",
      "2018-06-09 02:07:46    0.000237\n",
      "2018-06-09 02:07:47    0.000410\n",
      "2018-06-09 02:07:48    0.000265\n",
      "2018-06-09 02:07:49    0.000574\n",
      "2018-06-09 02:07:50    0.001254\n",
      "2018-06-09 02:07:51    0.000780\n",
      "2018-06-09 02:07:52    0.000896\n",
      "2018-06-09 02:07:53    0.001883\n",
      "2018-06-09 02:07:54    0.001908\n",
      "2018-06-09 02:07:55    0.001882\n",
      "2018-06-09 02:07:56    0.002002\n",
      "                         ...   \n",
      "2018-06-09 02:14:10   -0.000053\n",
      "2018-06-09 02:14:11    0.000493\n",
      "2018-06-09 02:14:12    0.000580\n",
      "2018-06-09 02:14:13    0.000195\n",
      "2018-06-09 02:14:14    0.000583\n",
      "2018-06-09 02:14:15    0.000115\n",
      "2018-06-09 02:14:16    0.000021\n",
      "2018-06-09 02:14:17    0.000005\n",
      "2018-06-09 02:14:18    0.000430\n",
      "2018-06-09 02:14:19    0.000239\n",
      "2018-06-09 02:14:20    0.000242\n",
      "2018-06-09 02:14:21   -0.000089\n",
      "2018-06-09 02:14:22    0.000002\n",
      "2018-06-09 02:14:23    0.000279\n",
      "2018-06-09 02:14:24    0.000280\n",
      "2018-06-09 02:14:25    0.000378\n",
      "2018-06-09 02:14:26    0.000439\n",
      "2018-06-09 02:14:27    0.000432\n",
      "2018-06-09 02:14:28   -0.000097\n",
      "2018-06-09 02:14:29   -0.000121\n",
      "2018-06-09 02:14:30    0.000008\n",
      "2018-06-09 02:14:31    0.000335\n",
      "2018-06-09 02:14:32    0.000445\n",
      "2018-06-09 02:14:33    0.000442\n",
      "2018-06-09 02:14:34    0.000483\n",
      "2018-06-09 02:14:35    0.000373\n",
      "2018-06-09 02:14:36   -0.000155\n",
      "2018-06-09 02:14:37   -0.000200\n",
      "2018-06-09 02:14:38   -0.000047\n",
      "2018-06-09 02:14:39    0.000009\n",
      "Freq: S, Name: N2, Length: 433, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "reject = 0\n",
    "for profile in range(0,2,2):\n",
    "    c_file = 'C'+(\"%07d\" % (profile,))\n",
    "    a_file = 'A'+(\"%07d\" % (profile,))\n",
    "    \n",
    "    data = create_data(directory, c_file, a_file)\n",
    "    data = buoyancy_freq(data)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wire3]",
   "language": "python",
   "name": "conda-env-wire3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
